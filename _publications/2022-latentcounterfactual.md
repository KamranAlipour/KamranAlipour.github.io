---
title: "Explaining Image Classifiers Using Contrastive Counterfactuals in Generative Latent Spaces"
collection: publications
permalink: /publication/2022-latentcounterfactual
excerpt: "Despite their high accuracies, modern complex image classifiers cannot be trusted for sensitive tasks due to their unknown decision-making process and potential biases. Counterfactual explanations are very effective in providing transparency for these black-box algorithms. Nevertheless, generating counterfactuals that can have a consistent impact on classifier outputs and yet expose interpretable feature changes is a very challenging task. We introduce a novel method to generate causal and yet interpretable counterfactual explanations for image classifiers using pretrained generative models without any re-training or conditioning. The generative models in this technique are not bound to be trained on the same data as the target classifier. We use this framework to obtain contrastive and causal sufficiency and necessity scores as global explanations for black-box classifiers. On the task of face attribute classification, we show how different attributes influence the classifier output by providing both causal and contrastive feature attributions, and the corresponding counterfactual images."
date: 2022-06-10
venue: 'Arxiv'
paperurl: 'https://arxiv.org/abs/2206.05257'
citation: "Alipour, K., Lahiri, A., Adeli, E., Salimi, B., Pazzani, M. (2022). Improving users' Explaining Image Classifiers Using Contrastive Counterfactuals in Generative Latent Spaces."
---
The paper proposes a novel method to generate causal and interpretable counterfactual explanations for image classifiers using pretrained generative models, allowing for transparency in black-box algorithms without the need for re-training or conditioning, and provides examples of the method's effectiveness in identifying how different attributes influence classifier outputs in face attribute classification.